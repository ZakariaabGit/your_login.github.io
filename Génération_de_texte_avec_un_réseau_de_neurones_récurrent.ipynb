{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TD2 : Génération de texte avec un réseau de neurones récurrent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwT7eyfZWqAraUcL4dmKe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZakariaabGit/zakariaabGit.github.io/blob/main/G%C3%A9n%C3%A9ration_de_texte_avec_un_r%C3%A9seau_de_neurones_r%C3%A9current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ascrzzAN4kT"
      },
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "def get_vocab(texte):\n",
        "  return np.unique(list(texte))\n",
        "\n",
        "\n",
        "\n",
        "def create_input_label(datasetBatch):\n",
        "\n",
        "    def split_input_target(chunk):\n",
        "        \"\"\" from https://www.tensorflow.org/tutorials/text/text_generation \"\"\"\n",
        "        input_text = chunk[:-1]\n",
        "        target_text = chunk[1:]\n",
        "        return input_text, target_text\n",
        "\n",
        "    dataset_split = datasetBatch.map(split_input_target)\n",
        "    return dataset_split\n",
        "\n",
        "\n",
        "def affiche_input_data(dataset_split, N, dico_int2char):\n",
        "\n",
        "    for input, target in dataset_split.take(N):\n",
        "        list_ch = [dico_int2char[i] for i in input.numpy()]\n",
        "        print(\"----Input : \", ''.join(list_ch))\n",
        "        list_ch = [dico_int2char[i] for i in target.numpy()]\n",
        "        print(\"----Label : \", ''.join(list_ch))\n",
        "\n",
        "\n",
        "def generate_text(model, start_string, char2idx, idx2char, num2generate=1000):\n",
        "    \"\"\" A COMPLETER 2.3 Génération du texte \"\"\"\n",
        "\n",
        "    # Question 1  : conversion de la séquence d'entrée start_string en séquence d'entiers\n",
        "    input_eval = None\n",
        "\n",
        "    eval_tensor = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    for i in range(num2generate):\n",
        "\n",
        "        # Question 2 : Prediction\n",
        "        pred_tensor = None\n",
        "\n",
        "\n",
        "        pred_tensor = tf.squeeze(pred_tensor, 0)  # suppression de la dimension du batch\n",
        "        predicted_int = tf.random.categorical(pred_tensor, num_samples=1)[\n",
        "            -1, 0].numpy()  # conversion du dernier caractère prédit en valeur numpy\n",
        "        eval_tensor = tf.expand_dims([predicted_int], 0)  # nouvelle entrée pour la future prédiction\n",
        "\n",
        "\n",
        "        # Question 3 : conversion de predicted_int en caractère\n",
        "\n",
        "\n",
        "        # Question 4 : stocker successivement les caractères prédits et retourner la séquence de caractère prédite\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    ### CHARGEMENT DES DONNEES\n",
        "    # Shakespeare\n",
        "    path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "    text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Drw_daKRrim"
      },
      "source": [
        "# 1.1 Observation du vocabulaire\n",
        "\n",
        "1. Dans la partie main (en dehors de la fonction dans un notebook), afficher les caractères et\n",
        "le nombre de caractères en utilisant la fonction get_vocab qui vous est donnée. La fonction\n",
        "get_vocab retourne l’ensemble des caractères (uniques) présents dans le texte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "TvYYTMfvQX1K",
        "outputId": "32ef9060-c9a1-43ff-f6d7-e201ebdc2037"
      },
      "source": [
        "a=get_vocab(text)\n",
        "print(a)\n",
        "print(\"nobmre de caractères : {}\".format(len(a)))\n",
        "a[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
            " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
            " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
            " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "nobmre de caractères : 65\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZuFnDz6R43V"
      },
      "source": [
        "# 1.2 Conversion du texte en entiers \n",
        "1. Au dessus du main, créer une fonction text2int qui convertit le texte en une séquence d’entiers.\n",
        "A chaque caractère est associé un entier entre 0 et le nombre de caractères. Pour cela, créer un\n",
        "dictionnaire associant chaque caractère à un entier. La fonction retourne une liste contenant\n",
        "la séquence d’entiers et le dictionnaire permettant la conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WhozTIGS2na"
      },
      "source": [
        "def text2int(text):\n",
        "  vocab=get_vocab(text)\n",
        "  l=[i for i in range(len(vocab))]\n",
        "  dic={}\n",
        "  liste=[]\n",
        "  i=0\n",
        "  for c in vocab:\n",
        "    \n",
        "    dic[c]=dic.get(c,i)\n",
        "    i+=1\n",
        "  #dic=_char2int={ch:idx for idx,ch in enumerate(vocab)}\n",
        "\n",
        "  for c in text:\n",
        "    if c in dic.keys():\n",
        "      liste.append(dic[c])\n",
        "  #text_int=[dic_char2int[ch] for ch in list(texte)]\n",
        "  return liste,dic\n",
        "\n",
        "\n",
        "  \n",
        "def text2int(texte):\n",
        "  vocab = get_vocab(texte)\n",
        "  dic_char2int = {ch:idx for idx, ch in enumerate(vocab)}\n",
        "  text_int = [dic_char2int[ch] for ch in list(texte)]\n",
        "\n",
        "  return dic_char2int, text_int"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW-gMu30YWxE"
      },
      "source": [
        "2. Dans le main, afficher les 45 premiers caractères du texte et les premiers entiers associés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3zhnkWsR-8J",
        "outputId": "3b088dd4-8159-4915-830f-7a27d6bb21a6"
      },
      "source": [
        "dico_char2int, text_int = text2int(text)\n",
        "print(\"Texte original : \", text[:45])\n",
        "print(\"Texte converti : \", text_int[:45])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texte original :  First Citizen:\n",
            "Before we proceed any further,\n",
            "Texte converti :  [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rksv50zYcK9"
      },
      "source": [
        "3. Construire un dictionnaire réalisant la conversion inverse du dictionnaire précédent : il a\n",
        "pour clé les entiers et pour valeur les caractères associés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ijXIg8Rq1b",
        "outputId": "06fda732-0ad3-489b-dbb6-97165823a3ed"
      },
      "source": [
        "dico_int2char = {idx:ch for ch,idx in dico_char2int.items()}\n",
        "print(dico_int2char)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: ' ', 2: ',', 3: ':', 4: 'B', 5: 'C', 6: 'F', 7: 'a', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'h', 13: 'i', 14: 'n', 15: 'o', 16: 'p', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'w', 22: 'y', 23: 'z'}\n",
            "dict_items([('\\n', 0), (' ', 1), (',', 2), (':', 3), ('B', 4), ('C', 5), ('F', 6), ('a', 7), ('c', 8), ('d', 9), ('e', 10), ('f', 11), ('h', 12), ('i', 13), ('n', 14), ('o', 15), ('p', 16), ('r', 17), ('s', 18), ('t', 19), ('u', 20), ('w', 21), ('y', 22), ('z', 23)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTTBQghbauFD"
      },
      "source": [
        "# 1.3 Formatage des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjiB1QGMTMJV"
      },
      "source": [
        "Ici, nous allons manipuler les données à travers la librairie tf.data.Dataset de Tensorflow qui\n",
        "créé un objet héritant du type Tensor. Construire une fonction create_examples qui réalise les\n",
        "opérations suivantes :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKYWTPawTVXo"
      },
      "source": [
        "1. Création d’un objet Dataset à partir d’une liste d’entiers donnée en argument (méthode\n",
        "from_tensor_slices,\n",
        "\n",
        "2. Retourne des exemples de longueurs seq_length (méthode batch), où seq_length est un\n",
        "argument de la fonction valant par défaut 101."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEiwcFfAbEDM"
      },
      "source": [
        "def create_examples(texte_int, seq_length=101):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(texte_int)\n",
        "  sequence_obs = dataset.batch(seq_length, drop_remainder=True)\n",
        "  return sequence_obs\n",
        "\n",
        "dataset1 = create_examples(text_int)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsKOdPRiT17c"
      },
      "source": [
        "La longueur 101 n’est pas totalement arbitraire : on va par la suite construire des exemples\n",
        "d’apprentissage en cherchant à prédire le dernier caractère de chaque donnée. On aura donc\n",
        "des exemples d’apprentissage de 100 caractères et on apprendra à prédire le 101ème."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCGnKldJet-2",
        "outputId": "6d9998b2-ea62-40db-be23-c3ffe630c1ea"
      },
      "source": [
        "dataset1=create_examples(text_int)\n",
        "print(dataset1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: (101,), types: tf.int32>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmbnDVSCT6h0"
      },
      "source": [
        "# 1.4 Création des observations (entrées) et labels\n",
        "La tâche ici sera d’entraîner le réseau à prédire le caractère suivant. La fonction create_input_label\n",
        "réalise un découpage de chaque exemple du batch pour construire l’entrée du réseau et son label\n",
        "associé. Ainsi :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60GCFzAHffzp"
      },
      "source": [
        "dataset_examples = create_input_label(dataset1)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC18KN75VcP3"
      },
      "source": [
        "affiche_input_data(dataset_examples, 3, dico_int2char)\n",
        "\n",
        "def create_batch(examples, batch_size=64):\n",
        "  return examples.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "BATCH_SIZE=32\n",
        "dataset_batch = create_batch(dataset_examples, batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1R-XkEVgwC"
      },
      "source": [
        "dataset_examples = create_input_label(dataset1)\n",
        "affiche_input_data(dataset_examples, 3, dico_int2char)\n",
        "\n",
        "def create_batch(examples, batch_size=64):\n",
        "  return examples.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "BATCH_SIZE=32\n",
        "dataset_batch = create_batch(dataset_examples, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}